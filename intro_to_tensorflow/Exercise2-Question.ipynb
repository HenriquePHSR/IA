{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOoyQ70H00_s"
   },
   "source": [
    "## Exercise 2\n",
    "In the course you learned how to do classificaiton using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
    "\n",
    "Some notes:\n",
    "1. It should succeed in less than 10 epochs, so it is okay to change epochs= to 10, but nothing larger\n",
    "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
    "3. If you add any additional variables, make sure you use the same names as the ones used in the class\n",
    "\n",
    "I've started the code for you below -- how would you finish it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henrique\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Henrique\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Henrique\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Henrique\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Henrique\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Henrique\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Henrique\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Henrique\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Henrique\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Henrique\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Henrique\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Henrique\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from os import path, getcwd, chdir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# DO NOT CHANGE THE LINE BELOW. If you are developing in a local\n",
    "# environment, then grab mnist.npz from the Coursera Jupyter Notebook\n",
    "# and place it inside a local folder and edit the path to that location\n",
    "path = f\"{getcwd()}/../tmp2/mnist.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rvXQGAA0ssC"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_mnist\n",
    "\n",
    "# Please write your code only where you are indicated.\n",
    "# please do not remove # model fitting inline comments.\n",
    "\n",
    "# YOUR CODE SHOULD START HERE\n",
    "\n",
    "# YOUR CODE SHOULD END HERE\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "# YOUR CODE SHOULD START HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rvXQGAA0ssC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.14901961\n",
      "  0.16862745 0.41176471 1.         0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.68235294 0.02352941 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.16862745 0.54509804 0.87843137\n",
      "  0.88627451 0.98823529 0.99215686 0.98823529 0.98823529 0.98823529\n",
      "  0.98823529 0.98823529 0.98823529 0.61960784 0.05490196 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.69803922 0.98823529 0.98823529\n",
      "  0.98823529 0.98823529 0.99215686 0.98823529 0.98823529 0.98823529\n",
      "  0.98823529 0.98823529 0.98823529 0.98823529 0.23137255 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.42745098 0.98823529 0.98823529\n",
      "  0.90196078 0.51764706 0.52156863 0.51764706 0.51764706 0.74117647\n",
      "  0.98823529 0.98823529 0.98823529 0.98823529 0.23137255 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01568627 0.11372549 0.11372549\n",
      "  0.09411765 0.         0.         0.         0.         0.05490196\n",
      "  0.88627451 0.98823529 0.98823529 0.6745098  0.02745098 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.33333333\n",
      "  0.95294118 0.98823529 0.98823529 0.56470588 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.34509804 0.74117647\n",
      "  0.98823529 0.98823529 0.98823529 0.05490196 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.35686275 0.83137255 0.96862745 0.98823529\n",
      "  0.98823529 0.98823529 0.8        0.03529412 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.1254902  0.49019608 0.75686275\n",
      "  0.75686275 0.75686275 0.99215686 0.98823529 0.98823529 0.98823529\n",
      "  0.93333333 0.4        0.10980392 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17647059 0.87058824 0.98823529 0.98823529\n",
      "  0.98823529 0.98823529 0.99215686 0.98823529 0.98823529 0.98823529\n",
      "  0.69411765 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17647059 0.8745098  0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 1.         0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.29019608 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.12156863 0.48235294 0.20392157\n",
      "  0.17254902 0.17254902 0.17254902 0.17254902 0.56078431 0.98823529\n",
      "  0.98823529 0.29019608 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05882353 0.98823529\n",
      "  0.98823529 0.29019608 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.3372549  0.98823529\n",
      "  0.98823529 0.29019608 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.01960784 0.29411765 0.03529412 0.         0.         0.\n",
      "  0.         0.         0.         0.38431373 0.94901961 0.98823529\n",
      "  0.98823529 0.29019608 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.23921569\n",
      "  0.71764706 0.98823529 0.11372549 0.         0.         0.\n",
      "  0.         0.07058824 0.36078431 0.9372549  0.98823529 0.98823529\n",
      "  0.95294118 0.25490196 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.81568627\n",
      "  0.98823529 0.98823529 0.57647059 0.5254902  0.5254902  0.5254902\n",
      "  0.5254902  0.79607843 0.99215686 0.98823529 0.98823529 0.7372549\n",
      "  0.3254902  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.81568627\n",
      "  0.98823529 0.98823529 0.98823529 0.98823529 0.98823529 0.98823529\n",
      "  0.98823529 0.98823529 0.99215686 0.90196078 0.6        0.03137255\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.19215686\n",
      "  0.61568627 0.98823529 0.98823529 0.98823529 0.98823529 0.98823529\n",
      "  0.85098039 0.81176471 0.57254902 0.17647059 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.02745098 0.40392157 0.92156863 0.98823529 0.6745098  0.40392157\n",
      "  0.09411765 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[7])\n",
    "print(y_train[7])\n",
    "print(x_train[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rvXQGAA0ssC"
   },
   "outputs": [],
   "source": [
    "#Normalize\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rvXQGAA0ssC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "59392/60000 [============================>.] - ETA: 0s - loss: 0.2613 - acc: 0.9252\n",
      "Reached 90% accuracy so cancelling training!\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2603 - acc: 0.9254\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.9):\n",
    "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "\n",
    "callbacks = myCallback()\n",
    "np.set_printoptions(linewidth=200)\n",
    "    \n",
    "# YOUR CODE SHOULD END HERE\n",
    "model = tf.keras.models.Sequential([\n",
    "        # YOUR CODE SHOULD START HERE\n",
    "        tf.keras.layers.Flatten(), \n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "    \n",
    "# model fitting\n",
    "history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "    x_train, y_train, epochs = 5, callbacks = [callbacks] \n",
    "              # YOUR CODE SHOULD END HERE\n",
    "    )\n",
    "# model fitting\n",
    "#return history.epoch, history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rvXQGAA0ssC"
   },
   "outputs": [],
   "source": [
    "model.predict(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above.\n",
    "# Once that is complete, please run the following two cells to save your work and close the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "introduction-tensorflow",
   "graded_item_id": "d6dew",
   "launcher_item_id": "FExZ4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
